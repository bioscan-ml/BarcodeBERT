{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ffcc44-0615-4a36-b36b-d12d8d69739b",
   "metadata": {},
   "source": [
    "# ZSC Comparsion of Different Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513070a3-b164-40cd-a5bf-12a4f7ddb9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmillana/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmillana/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 29536512\n",
      "Using device: cuda\n",
      "Calculating embeddings for BarcodeBERT\n",
      "embeddings//BIOSCAN-5M/BarcodeBERT/unseen.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/BarcodeBERT/unseen.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(3396, 768)\n",
      "Using device: cuda\n",
      "Calculating embeddings for BarcodeBERT\n",
      "embeddings//BIOSCAN-5M/BarcodeBERT/supervised_test.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/BarcodeBERT/supervised_test.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(18348, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6045013/pmillana/BarcodeBERT/baselines/models/dnabert2.py:203: UserWarning: Unable to import Triton; defaulting MosaicBERT attention                 implementation to pytorch (this will reduce throughput when using this model).\n",
      "  self.self = BertUnpadSelfAttention(config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 117068544\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-2\n",
      "embeddings//BIOSCAN-5M/DNABERT-2/unseen.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/DNABERT-2/unseen.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(3396, 768)\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-2\n",
      "embeddings//BIOSCAN-5M/DNABERT-2/supervised_test.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/DNABERT-2/supervised_test.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(18348, 768)\n",
      "Number of trainable parameters: 117068544\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-S\n",
      "embeddings//BIOSCAN-5M/DNABERT-S/unseen.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/DNABERT-S/unseen.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(3396, 768)\n",
      "Using device: cuda\n",
      "Calculating embeddings for DNABERT-S\n",
      "embeddings//BIOSCAN-5M/DNABERT-S/supervised_test.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/DNABERT-S/supervised_test.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(18348, 768)\n",
      "Number of trainable parameters: 55904972\n",
      "Using device: cuda\n",
      "Calculating embeddings for NT\n",
      "embeddings//BIOSCAN-5M/NT/unseen.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/NT/unseen.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(3396, 512)\n",
      "Using device: cuda\n",
      "Calculating embeddings for NT\n",
      "embeddings//BIOSCAN-5M/NT/supervised_test.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/NT/supervised_test.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(18348, 512)\n",
      "Loaded pretrained weights ok!\n",
      "Number of trainable parameters: 436096\n",
      "Using device: cuda\n",
      "Calculating embeddings for Hyena_DNA\n",
      "embeddings//BIOSCAN-5M/Hyena_DNA/unseen.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/Hyena_DNA/unseen.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(3396, 128)\n",
      "Using device: cuda\n",
      "Calculating embeddings for Hyena_DNA\n",
      "embeddings//BIOSCAN-5M/Hyena_DNA/supervised_test.pickle\n",
      "We found the file embeddings//BIOSCAN-5M/Hyena_DNA/supervised_test.pickle. It seems that we have computed the embeddings ... \n",
      "\n",
      "Loading the embeddings from that file\n",
      "(18348, 128)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('.')\n",
    "from baselines.datasets import representations_from_df, labels_from_df \n",
    "from baselines.io import load_baseline_model\n",
    "\n",
    "data_folder = \"../data_BIOSCAN/BIOSCAN_5M\"\n",
    " \n",
    "#\"BarcodeBERT_soft_penalty/data\"\n",
    "\n",
    "for model_name in [\"BarcodeBERT\", \"DNABERT-2\", \"DNABERT-S\", \"NT\", \"Hyena_DNA\"]:\n",
    "        embedder = load_baseline_model(model_name)\n",
    "    \n",
    "        embedder.name = model_name\n",
    "        \n",
    "        # Ensure model is in eval mode\n",
    "        embedder.model.eval()\n",
    "    \n",
    "        trainable_params = sum(\tp.numel() for p in embedder.model.parameters() if p.requires_grad)\n",
    "    \n",
    "        print(f\"Number of trainable parameters: {trainable_params}\")\n",
    "        \n",
    "        for file in [\"unseen\", \"supervised_test\"]: \n",
    "            filename = f\"{data_folder}/{file}.csv\"\n",
    "            embeddings = representations_from_df(filename, embedder, dataset=\"BIOSCAN-5M\", target=\"processid\") #dataset= \"BIOSCAN-5M\"\n",
    "            print(embeddings[\"data\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ec23a-2404-4a01-8369-9385dd4aba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bioscan-ml/BarcodeBERT\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"bioscan-ml/BarcodeBERT\", trust_remote_code=True)\n",
    "\n",
    "model(torch.tensor(input_seq)tokenizer.tokenize('ACGCGCTGCGACGCAT', return_tensors = 'pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66251b79-101f-41d0-9696-54e0adf73978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bioscan-ml/BarcodeBERT\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"bioscan-ml/BarcodeBERT\", trust_remote_code=True)\n",
    "\n",
    "dna_seq = 'ACGCGCTGACGCATCAGCATACGA'\n",
    "input_seq = input_seq = tokenizer.tokenize(dna_seq, return_tensors = 'pt') #tokenizer(dna_seq, return_tensors = 'pt')\n",
    "print(input_seq)\n",
    "\n",
    "print(model(input_seq['input_ids']))['hidden_states'][-1]\n",
    "\n",
    "# hidden_states = model(inputs)[0] # [1, sequence_length, 768]\n",
    "\n",
    "# # embedding with mean pooling\n",
    "# embedding_mean = torch.mean(hidden_states[0], dim=0)\n",
    "# print(embedding_mean.shape) # expect to be 768\n",
    "\n",
    "# # embedding with max pooling\n",
    "# embedding_max = torch.max(hidden_states[0], dim=0)[0]\n",
    "# print(embedding_max.shape) # expect to be 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567737a1-7480-4f4f-996d-21e7ae15ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = tokenizer.tokenize(dna_seq)\n",
    "print(torch.tensor(input_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6718c-53f4-40c8-92b4-df5785a1948b",
   "metadata": {},
   "source": [
    "### This notebook Compares the embedding performance on the 'BIOSCAN-5M' dataset, of seven different DNA barcode-based models: BarcodeBERT-1M, BarcodeBERT-5M, DNABERT, DNABERT-2, DNABERT-S, Hyena_DNA and NT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2971b2-f24a-41f8-8155-ffc35fbe23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import cProfile\n",
    "import pstats\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier, KDTree\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from obj_knn import FinBOL_GBOL\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = \"BIOSCAN-5M\"\n",
    "data_folder = \"../data_BIOSCAN/BIOSCAN_5M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c832d9-c6b0-4008-a8db-4cc40438127a",
   "metadata": {},
   "source": [
    "### Each sample is labeled at seven taxonomic ranks: class, order, family, subfamily, tribe, genus, and species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11db4831-2ade-4dd4-8d68-f47a93c66bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank_list = [\"class\", \"order\", \"family\", \"genus\", \"species\", \"dna_bin\"]\n",
    "rank_list = [\"dna_bin\"]\n",
    "#rank_list = [\"species\"]\n",
    "encoders = [\"baseline_enc\", \"MAE-LM\", ]#\"BarcodeMamba\", \"Caduceus\", \"BarcodeBERT\", \"DNABERT-2\", \"DNABERT-S\", \"Hyena_DNA\", \"NT\"] #, \"DNABERT\"]\n",
    "\n",
    "# Creating the embeddings dictionary to hold all the FinBOL vs GBOL embedding/label data \n",
    "embeddings = {}\n",
    "for encoder in encoders:\n",
    "    embeddings[encoder] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff05da-a071-4014-9454-47615bb4b1f4",
   "metadata": {},
   "source": [
    "### We load embeddings from the test and the unseen_test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3be74c3-42d5-4587-9622-af7d6d85bd80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m embeddings_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/pmillana/projects/def-lila-ab/pmillana/BarcodeBERT/embeddings/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/supervised_test.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m train_handle:\n\u001b[0;32m----> 6\u001b[0m     embeddings[encoder][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeen\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(train_handle)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# reading the Unseen embeddings\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/unseen.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m test_handle:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "dataset=\"BIOSCAN-5M\"\n",
    "for encoder in encoders:\n",
    "    # reading the Seen embeddings\n",
    "    embeddings_folder = f\"/home/pmillana/projects/def-lila-ab/pmillana/BarcodeBERT/embeddings/{dataset}\"\n",
    "    with open(f\"{embeddings_folder}/{encoder}/supervised_test.pickle\", \"rb\") as train_handle:\n",
    "        embeddings[encoder][\"Seen\"] = pickle.load(train_handle)\n",
    "\n",
    "    # reading the Unseen embeddings\n",
    "    with open(f\"{embeddings_folder}/{encoder}/unseen.pickle\", \"rb\") as test_handle:\n",
    "        embeddings[encoder][\"Unseen\"] = pickle.load(test_handle)\n",
    "\n",
    "print('Partition lengths:')\n",
    "print(\"Train: \", len(embeddings[encoder][\"Seen\"]['ids']))\n",
    "print(\"Test: \", len(embeddings[encoder][\"Unseen\"]['ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644340ab-9243-49be-903c-7b35ec77643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_enc\n",
      "CRPEB17249-21\n",
      "CRPEA1108-21\n",
      "CRPEB5181-21\n",
      "\n",
      "MAE-LM\n",
      "CRPEB17249-21\n",
      "CRPEA1108-21\n",
      "CRPEB5181-21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for encoder in encoders:\n",
    "    print(encoder)\n",
    "    for x in (embeddings[encoder][\"Unseen\"]['ids'][0:3]):\n",
    "        print(x)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034cfca-ecb9-45a8-8688-45b5726e81d7",
   "metadata": {},
   "source": [
    "### Each model encodes a different represenation of the data it was given. To see this, and check that all the data from each model was downloaded properly, a small slice of each encoder's first three embeddings is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "837fc9a6-974a-4a53-a7cf-56bf17d2f5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_enc\n",
      "[ 0.08005197 -0.3515328   0.0466208  -0.11751309  0.2454242 ]\n",
      "[ 1.6977788  -0.30647355 -0.14215916 -0.20202906  0.52943826]\n",
      "[-0.02211483 -0.30919886 -0.77613413  0.35126758  0.21534416]\n",
      "\n",
      "MAE-LM\n",
      "[ 0.02388948  0.3316227   0.3033988  -0.21507314  0.36268246]\n",
      "[-0.4483601  -0.6371719  -0.1814654  -0.02485802  1.0681458 ]\n",
      "[-0.6162105   0.6405595  -0.48441413  0.7026382   0.25358397]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking embeddings have been loaded correctly for each model\n",
    "for encoder in encoders:\n",
    "    print(encoder)\n",
    "    for x in (embeddings[encoder][\"Seen\"]['data'][0:3]):\n",
    "        print(x[0:5])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06d6f8-c88e-45e1-8627-8046456bf268",
   "metadata": {},
   "source": [
    "### After reading the embedding files from each model, the labels associated with each embeddings must be further processed in order to be used in the ZSC. A single sample from the file contains a 'data' segment (the embedding), and a 'ids' segments which contains a label that holds several different kinds of information about that specific sample. It is this 'ids' segment that must be seperated into several more specific segments including the label of that sample at each of the seven taxonomic ranks listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f298101-7bb2-41ce-989f-4cfadd8da978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(f\"{data_folder}/supervised_test.csv\")\n",
    "test = pd.read_csv(f\"{data_folder}/unseen.csv\")\n",
    "\n",
    "df_dict = {'Seen': train, 'Unseen':test}\n",
    "\n",
    "for encoder in encoders:\n",
    "    for part in ('Seen', 'Unseen'):\n",
    "        df = df_dict[part]\n",
    "        for rank in rank_list:\n",
    "            if rank not in ['class', 'dna_bin']:\n",
    "                taxa = rank + '_name'\n",
    "            else:\n",
    "                taxa = rank\n",
    "            processid_to_taxa = dict(zip(df['processid'], df[taxa]))\n",
    "            # extract label at each taxonomic rank\n",
    "            embeddings[encoder][part][rank] = [processid_to_taxa.get(processid, None) for processid in embeddings[encoder][part]['ids']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977504e-99ec-4952-9f17-1127dabadc28",
   "metadata": {},
   "source": [
    "### After processing the initial label, each sample now has 10 distinct labels that can be used to group and identify them. Below is an example of the labels concerning the first sample of the FinBOL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab3ba62-fa27-4689-bd2f-6c8370967567",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BarcodeBERT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE-LM\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeen\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(x))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m ,\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBarcodeBERT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeen\u001b[39m\u001b[38;5;124m'\u001b[39m][x][\u001b[38;5;241m13\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BarcodeBERT'"
     ]
    }
   ],
   "source": [
    "# displaying all the new labels\n",
    "for x in embeddings['MAE-LM']['Seen'].keys():\n",
    "    if x != 'data':\n",
    "        print(f\"{x}:{' '*(10-len(x))}\" ,embeddings['BarcodeBERT']['Seen'][x][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939c9389-4894-4c7c-a10f-ea50639a5625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processid</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order_name</th>\n",
       "      <th>family_name</th>\n",
       "      <th>subfamily_name</th>\n",
       "      <th>genus_name</th>\n",
       "      <th>species_name</th>\n",
       "      <th>dna_bin</th>\n",
       "      <th>nucleotides</th>\n",
       "      <th>split</th>\n",
       "      <th>phylum_index</th>\n",
       "      <th>class_index</th>\n",
       "      <th>order_index</th>\n",
       "      <th>family_index</th>\n",
       "      <th>subfamily_index</th>\n",
       "      <th>genus_index</th>\n",
       "      <th>species_index</th>\n",
       "      <th>dna_bin_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CRPEB17386-21</td>\n",
       "      <td>Arthropoda</td>\n",
       "      <td>Malacostraca</td>\n",
       "      <td>Amphipoda</td>\n",
       "      <td>Brevitalitridae</td>\n",
       "      <td>unassigned Brevitalitridae</td>\n",
       "      <td>Talitroides</td>\n",
       "      <td>Talitroides topitotum</td>\n",
       "      <td>BOLD:AAV0705</td>\n",
       "      <td>TTATACTTCATTTTAGGTGCTTGGGCTAGAGTTATTGGTACCTCTT...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>250</td>\n",
       "      <td>520</td>\n",
       "      <td>503</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        processid      phylum         class order_name      family_name  \\\n",
       "13  CRPEB17386-21  Arthropoda  Malacostraca  Amphipoda  Brevitalitridae   \n",
       "\n",
       "                subfamily_name   genus_name           species_name  \\\n",
       "13  unassigned Brevitalitridae  Talitroides  Talitroides topitotum   \n",
       "\n",
       "         dna_bin                                        nucleotides split  \\\n",
       "13  BOLD:AAV0705  TTATACTTCATTTTAGGTGCTTGGGCTAGAGTTATTGGTACCTCTT...  test   \n",
       "\n",
       "    phylum_index  class_index  order_index  family_index  subfamily_index  \\\n",
       "13             0            4            0            35              250   \n",
       "\n",
       "    genus_index  species_index  dna_bin_index  \n",
       "13          520            503            460  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['Seen'][df_dict['Seen'][\"processid\"]==\"CRPEB17386-21\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3bdd5-dd54-4a5b-87ef-83cdab41b570",
   "metadata": {},
   "source": [
    "### A single dictionary called 'embeddings' now holds all the data and labels associated with each sample, for each partition, for each model. This example shows the general tree structure for how the data is accessed for each model where each key holds another dictionary except for those at the lowest level which are lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc79d5-1152-4e16-82be-afcb551d481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.keys())\n",
    "print(embeddings['NT'].keys())\n",
    "print(embeddings['NT']['Unseen'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fddc39-450d-4596-9305-cc4f664967c6",
   "metadata": {},
   "source": [
    "# ZSC Analysis\n",
    "the results following the section as well as the associated output files for each model have been made using k=10 for the KNN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "662e751d-6615-44a6-b2de-0ad4315c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "\n",
    "def zsc_pipeline(X, y_true):\n",
    "        \n",
    "    # Step 1: Dimensionality reduction with UMAP to 50 dimensions\n",
    "    umap_reducer = umap.UMAP(n_components=50, random_state=42, metric=\"cosine\", n_neighbors=10)\n",
    "    X_reduced = umap_reducer.fit_transform(X)\n",
    "    \n",
    "    # Step 2: Cluster the reduced embeddings with Agglomerative Clustering (L2, Ward’s method)\n",
    "    agglomerative_clustering = AgglomerativeClustering(n_clusters=4363, linkage='ward')\n",
    "    cluster_labels = agglomerative_clustering.fit_predict(X_reduced)\n",
    "    \n",
    "    # Step 3: Evaluate clustering performance with Adjusted Mutual Information (AMI) score\n",
    "    ami_score = adjusted_mutual_info_score(y_true, cluster_labels)\n",
    "    \n",
    "    print(\"Adjusted Mutual Information (AMI) score:\", ami_score) \n",
    "    return ami_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73734663-fb80-4c4b-a149-1f948531c626",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "baseline_enc   :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6792, 768) (6792,)\n",
      "\n",
      "Intel MKL ERROR: Parameter 6 was incorrect on entry to DLASWP.\n",
      "\n",
      "Intel MKL ERROR: Parameter 6 was incorrect on entry to DLASWP.\n",
      "\n",
      "Intel MKL ERROR: Parameter 6 was incorrect on entry to DLASWP.\n",
      "\n",
      "Intel MKL ERROR: Parameter 6 was incorrect on entry to DLASWP.\n"
     ]
    }
   ],
   "source": [
    "# dictionaries for storing results and knn probability data\n",
    "results = {}\n",
    "label_probs = {}\n",
    "\n",
    "for encoder in encoders:\n",
    "    results[encoder] = {}\n",
    "\n",
    "    # using tqdm to display progress bar for each model\n",
    "    for i in tqdm(range(len(rank_list)),desc=f\"{encoder}{' '*(15-len(encoder))}\"):\n",
    "        rank=rank_list[i]\n",
    "        results[encoder][rank] = {}\n",
    "\n",
    "        # creating a number mapping for the labels at the current taxonomic rank to use for the analysis\n",
    "        #all_labels = sorted(list(set(embeddings[encoder]['Unseen'][rank]+embeddings[encoder]['Seen'][rank])))\n",
    "        #embeddings[encoder]['Seen']['mapped_y_true'] = np.array([all_labels.index(el) for el in embeddings[encoder]['Seen'][rank]])\n",
    "        #embeddings[encoder]['Unseen']['mapped_y_true'] = np.array([all_labels.index(el) for el in embeddings[encoder]['Unseen'][rank]])\n",
    "        \n",
    "        partition_name = \"test_seen + unseen\"\n",
    "        X_part = np.vstack([embeddings[encoder]['Seen']['data'], embeddings[encoder]['Unseen']['data']])\n",
    "        y_part = np.hstack([embeddings[encoder]['Seen'][rank], embeddings[encoder]['Unseen'][rank]])\n",
    "\n",
    "        print(X_part.shape, y_part.shape)\n",
    "            \n",
    "        # ZSC-accuracy\n",
    "        res_part = {}\n",
    "        res_part[\"count\"] = len(y_part)\n",
    "        # Note that these evaluation metrics have all been converted to percentages\n",
    "        res_part[\"AMI\"] = 100.0 * zsc_pipeline(X_part, y_part)\n",
    "        results[encoder][rank][partition_name] = res_part\n",
    "        print(res_part[\"AMI\"])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda9c32-c3e4-4504-970b-45ac4245236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7815b-8331-47a5-be58-0b90084bdfad",
   "metadata": {},
   "source": [
    "# Results\n",
    "### The results of the analysis are shown below in two different formats\n",
    "NOTE: The metric displayed in the graphs below is accuracy. Several other metrics have been calculated such as the balanced accuracy, all of which are stored in the 'results' dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e69d2a-c1b3-4fd7-bc15-380e7cc2e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"results_{dataset}_ZSC.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c81b18bc-c1f9-4ebd-8548-deba1c7241ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results_BIOSCAN-5M_ZSC.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#data_folder = \"BIOSCAN_5M_DNA_experiments/data\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_ZSC.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     24\u001b[0m     results \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     26\u001b[0m rank_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdna_bin\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2023b/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results_BIOSCAN-5M_ZSC.json'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import cProfile\n",
    "import pstats\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier, KDTree\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from obj_knn import FinBOL_GBOL\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = \"BIOSCAN-5M\"\n",
    "#data_folder = \"BIOSCAN_5M_DNA_experiments/data\"\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f\"results_{dataset}_ZSC.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "rank_list = [\"class\", \"order\", \"family\", \"genus\", \"species\", \"dna_bin\"]\n",
    "encoders = [\"BarcodeBERT\", \"DNABERT-2\", \"DNABERT-S\", \"Hyena_DNA\", \"NT\"]#, \"DNABERT\"]\n",
    "\n",
    "x = np.arange(len(rank_list))  # the label locations\n",
    "encoders = sorted(encoders,key=lambda x:results[x]['class']['test_seen + unseen']['AMI'],reverse=True)\n",
    "width = 0.15  # the width of the bars\n",
    "multiplier = -1\n",
    "\n",
    "graph = {}\n",
    "for encoder in encoders:\n",
    "    graph[encoder] = [round(results[encoder][rank]['test_seen + unseen']['AMI'], 2) for rank in rank_list]\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "for rank, measurement in graph.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=rank)\n",
    "    multiplier += 1\n",
    "\n",
    "for i in range(len(x)):\n",
    "    for j, encoder in enumerate(encoders):\n",
    "        plt.text(i+offset+(j-multiplier)*(width)+0.1, graph[encoder][i], graph[encoder][i], ha='center', rotation=60, fontsize='x-small')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Rank')\n",
    "\n",
    "ax.set_title('BIOSCAN-5M ZSC encoder comparison')\n",
    "ax.set_xticks(x + width, rank_list)\n",
    "ax.legend(loc='upper right', ncols=2)\n",
    "ax.set_ylim(0, 110)\n",
    "plt.grid(axis=\"y\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa782ca-45e3-4193-a3f8-e409a4103c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[\"#C154A0\", \"#6495ED\", \"#FFBF00\", \"#922B21\", \"#1E8449\", \"#40E0D0\", \"#C18420\"])\n",
    "\n",
    "\n",
    "encoders = [\"DNABERT-2\", \"DNABERT-S\", \"NT\", \"Hyena_DNA\",  \"BarcodeBERT\"] #, \"BarcodeBERT-5M\"]\n",
    "\n",
    "for encoder in encoders:\n",
    "    plt.plot(rank_list, graph[encoder],\"D-\", label = encoder)\n",
    "#plt.title('1NN-probing at different taxonomic levels')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"BIOSCAN_5M_KNN_by_rank_cosine.eps\", dpi=150)\n",
    "plt.savefig(\"BIOSCAN_5M_KNN_by_rank_cosine.jpg\", dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
